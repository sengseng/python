# -*- coding: utf-8 -*-
import datetime
import urllib2
import requests
from DBUtils.PooledDB import PooledDB
import MySQLdb
import pandas as pd

from selenium import webdriver
from selenium.webdriver.common.action_chains import ActionChains
import time
import SQLTools
from PIL import Image
import pytesseract
import re
import os
from selenium.common.exceptions import StaleElementReferenceException

import json

#全局常量
#截取图片保存路径
path=os.getcwd()
# 月份-日字典
Monthdict = {'01': 31, '02': 28, '03': 31, '04': 30, '05': 31, '06': 30, '07': 31, '08': 31, '09': 30, '10': 31,
             '11': 30, '12': 31, '1': 31, '2': 28, '3': 31, '4': 30, '5': 31, '6': 30, '7': 31, '8': 31, '9': 30}
#全局变量
inputid=''
name=''
#------------------------------------Spider流程#------------------------------------#

#初始化数据库并且创建文件本地保存目录
def init_sys():
     try:
        #读取Xml并初始化SQL
        SQLTools.InitSql('******','**','*****','*****','utf8')
        #创建文件本地保存目录
        if(os.path.exists(path+"/raw")) is False:
            os.mkdir(path+"/raw")
        if (os.path.exists(path + "/crop")) is False:
            os.mkdir(path + "/crop")
        if (os.path.exists(path + "/zoom")) is False:
            os.mkdir(path + "/zoom")
        return True
     except Exception,e :
         print e.message
         return False

#从数据库读取任务,返回Request list
def load_req():
    global name
    #获取任务
    input_item=SQLTools.GetInputFromDB()
    #(keyword,time)
    if input_item!=-1:
        name=input_item[0]
        print input_item[1]
        day=str(input_item[1])[6:8]
        month = str(input_item[1])[4:6]
        year = str(input_item[1])[0:4]
        input_id=input_item[2]
        print "正在获取",name.encode("utf-8"),"的百度指数"
        return [name,year,month,day,input_id]
    else:
        return False

#初始化Spiderk 模拟登录 提供browser工具类
def init_spider():
     try:
        url = "http://index.baidu.com/"#百度指数网站
        browser = webdriver.Chrome()
        browser.get(url)
        # 点击网页的登录按钮
        browser.find_element_by_xpath("//span[@class='username-text']").click()
        time.sleep(3)
        #传入账号密码
        browser.find_element_by_id("TANGRAM__PSP_4__password").send_keys('wasdZ123')
        browser.find_element_by_id("TANGRAM__PSP_4__userName").send_keys('18620384353'.encode("utf-8"))
        browser.find_element_by_id("TANGRAM__PSP_4__submit").click()
        time.sleep(10)
        js = 'document.getElementById("TANGRAM__14__mask").style.display="none";'
        js2 = 'document.getElementById("TANGRAM__14__wrapper").style.display="none";'
        browser.execute_script(js)
        browser.execute_script(js2)
        browser.find_element_by_id("TANGRAM__PSP_4__submit").click()
        time.sleep(3)
        return browser
     except:
         return False

#执行Spider 返回数据结果
def exec_spider(request):
    #request(name,year,month,day)
    global browser
    try:
        name=request[0]
        year=request[1]
        month=request[2]
        day=request[3]

        try:
            # 清空网页输入框
            browser.find_element_by_class_name("search-input").clear()
            # 写入需要搜索的百度指数
            browser.find_element_by_class_name("search-input").send_keys(name)
            # 点击搜索
            browser.find_element_by_class_name("search-input-cancle").click()
        except:
            browser.find_element_by_id("schword").clear()
            # 写入需要搜索的百度指数
            browser.find_element_by_id("schword").send_keys(name)
            # 点击搜索
            try:
                browser.find_element_by_id("searchWords").click()
            except:
                browser.find_element_by_id("schsubmit").click()

        time.sleep(2)

        browser.maximize_window()
        browser.find_elements_by_xpath("//div[@class='box-toolbar']/a")[1].click()
        time.sleep(5)

        return CollectIndex(browser,year,month,day,name)
    except IndexError,e:
        print e
        if Anti_Exist(browser) is True:
            browser.close()
            time.sleep(100)
            browser=init_spider()
            return exec_spider(request)
        else:
            return False
    except StaleElementReferenceException,e2:
        browser.close()
        time.sleep(100)
        browser=init_spider()
        return exec_spider(request)

#对抗反爬机制
def Anti_Exist(browser):
    try:
        browser.find_element_by_xpath("//img[@src='/static/imgs/deny.png']")
        return  True
    except:
        return False


#----------------------------------Spider运行过程中所需的方法----------------------------------#
def CollectIndex(browser,year,month,day,name):
    #初始化输出String
    OutputString='['
    x_0 = 1
    y_0 = 1
    ran=0
    # 根据起始具体日子计算鼠标的初始位置
    x_0 = x_0+202.5 * ran

    xoyelement = browser.find_elements_by_css_selector("#trend rect")[2]
    ActionChains(browser).move_to_element_with_offset(xoyelement, x_0, y_0).perform()
    if int(day) >= 7:
        day = int(day) - 7
    else:
        day = Monthdict[month] + int(day) - 7
        month = int(month) - 1
        if month == 0:
            year = int(year) - 1
            month = 2

    for i in range(7):
        # 计算当前得到指数的时间
        if int(month) < 10:
            month = '0' + str(int(month))
        if int(day) >= Monthdict[str(month)] + 1:
            day = 1
            month = int(month) + 1
            if month == 13:
                year = int(year) + 1
                month = 1
        time.sleep(1)
        # 获取Code
        code = GetTheCode(browser, year, month, day, name, path, xoyelement, x_0, y_0)
        # ViewBox不出现的循环
        cot = 0
        jud = True
        # print code
        while (code == None):
            cot += 1
            code = GetTheCode(browser, year, month, day, name, path, xoyelement, x_0, y_0)
            if cot >= 6:
                jud = False
                break
        if jud:
            anwserCode = code.group()
        else:
            anwserCode = str(-1)
            if int(day) < 10:
                day = '0' + str(int(day))
            if int(month) < 10:
                month = '0' + str(int(month))
        OutputString += str(year) + '-' + str(month) + '-' + str(day) + ':' + str(anwserCode) + ','
        x_0 = x_0 + 202.5
        day = int(day) + 1
        print anwserCode
    OutputString+=']'
    print OutputString
    return OutputString.decode('utf-8')

def GetTheCode(browser,fyear,fmonth,day,name,path,xoyelement,x_0, y_0):
    ActionChains(browser).move_to_element_with_offset(xoyelement, x_0, y_0).perform()
    #鼠标重复操作直到ViewBox出现
    cot=0
    while (ExistBox(browser)==False):
        cot+=1
        ActionChains(browser).move_to_element_with_offset(xoyelement, x_0, y_0).perform()
        if ExistBox(browser)==True:
            break
        if cot==6:
            return None

    imgelement = browser.find_element_by_xpath('//div[@id="viewbox"]')
    locations = imgelement.location
    printString = str(fyear) + "-" + str(fmonth) + "-" + str(day)
    # 找到图片位置
    l = len(name)
    if l > 8:
        l = 8
    rangle = (int(int(locations['x'])) + l * 10 + 38, int(int(locations['y'])) + 28,
              int(int(locations['x'])) + l * 10 + 38 + 75,
              int(int(locations['y'])) + 56)
    #保存截图
    browser.save_screenshot(str(path) + "/raw/" + printString + ".png")
    img = Image.open(str(path) + "/raw/" + printString + ".png")
    if locations['x'] != 0.0:
         #按Rangle截取图片
        jpg = img.crop(rangle)
        imgpath = str(path) + "/crop/" + printString + ".jpg"
        jpg.save(imgpath)
        jpgzoom = Image.open(str(imgpath))
        #放大图片
        (x, y) = jpgzoom.size
        x_s = 60 * 10
        y_s = 20 * 10
        out = jpgzoom.resize((x_s, y_s), Image.ANTIALIAS)
        out.save(path + "/zoom/" + printString, 'jpeg', quality=95)
        image = Image.open(path + "/zoom/" + printString)
        #识别图片
        code = pytesseract.image_to_string(image)
        regex = "\d+"
        pattern = re.compile(regex)
        dealcode = code.replace("S", '5').replace(" ", "").replace(",", "").replace("E", "8").replace(".", ""). \
            replace("'", "").replace(u"‘", "").replace("B", "8").replace("\"", "").replace("I", "1").replace(
            "i", "").replace("-", ""). \
            replace("$", "8").replace(u"’", "").strip()
        match = pattern.search(dealcode)
        return match
    else:
        return None

#判断ViewBox是否存在
def ExistBox(browser):
    try:
        browser.find_element_by_xpath('//div[@id="viewbox"]')
        return True
    except:
        return False

#百度指数
def _baidu_index():
    global browser
    #status记录初始化状态
    status=init_sys()
    if status is False:
        exit(1)
    # status记录工具类
    status = init_spider()
    ticot=0
    if status is False:
        exit(3)
    else:
        browser = status
    while True:
        SQLTools.Renew()
        # status记录Request
        status=load_req()
        if status is False:
            exit(2)
        else:
            request = status
            #request=[name,year,month,day,id]
        # status记录结果
        status = exec_spider(request)
        if status is False:
            print name, 'Error'
            SQLTools.AlterStatus("update program_public_sentiment_index set status=-1 where programid=" + str(request[4]) + ";")
            continue
        else:
            resultString = status.replace("\"", "")
            resultString1 = json.dumps(resultString)
            resultString1 = resultString1[2:len(resultString1)-3]
            resultString1 = resultString1.split(",")
            _max = resultString1[0].split(":")[1]
            for _result in resultString1:
                _cur = _result.split(":")[1]
                if _max < _cur:
                    _max = _cur
                else:
                    continue
        print "将结果保存到数据库", ticot
        ticot += 1
        # 保存到数据库中
        SQLTools.SaveResultToDB(_max, request[4])
        SQLTools.AlterStatus("update program_public_sentiment_index set status=1 where programid=" + str(request[4]) + ";")
        # 获取下一条
        print "休息"
        time.sleep(10)
        print "获取下一条数据"

###计算微博指数
def weibo_index(search_name,s_date,e_date):
    weibo_search_name = search_name
    weibo_search_name = weibo_search_name.encode('utf-8')
    url_name = urllib2.quote(weibo_search_name)
    print "search_name", search_name
    url_format = "http://data.weibo.com/index/ajax/hotword?word={}&flag=nolike&_t=0"
    cookie_header = {
        "User-Agent": "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.81 Safari/537.36",
        "Referer": "http://data.weibo.com/index?sudaref=www.google.com"
    }
    first_requests = url_format.format(url_name)
    codes = requests.get(first_requests, headers=cookie_header).json()
    if (codes["data"] != "null"):
        print codes["data"]
        ids = codes["data"]["id"]
        ### 获取相应时间内的微博指数
        header = {
            "Connection": "keep-alive",
            "Accept-Encoding": "gzip, deflate, sdch",
            "Accept": "*/*",
            "User-Agent": "Mozilla/5.0 (iPhone; CPU iPhone OS 9_2 like Mac OS X) AppleWebKit/601.1.46 (KHTML, like Gecko) Version/9.0 Mobile/13C75 Safari/601.1",
            "Accept-Language": "zh-CN,zh;q=0.8",
            "Referer": "http://data.weibo.com/index/hotword?wid={}&wname={}".format(ids, url_name),
            "Content-Type": "application/x-www-form-urlencoded",
            "Host": "data.weibo.com"
        }

        date_url = "http://data.weibo.com/index/ajax/getdate?month=default&__rnd=1498190033389"
        dc = requests.get(date_url, headers=header).json()
        edate, sdate = s_date, e_date

        # ## 数据返回
        codes = requests.post("http://data.weibo.com/index/ajax/newindex/getchartdata".format(ids), headers=header,
                              data={'wid': ids,'dateGroup':'1month', 'edate': edate, 'sdate': sdate}).json()
        if codes['code'] != 100:
            max_index = codes['msg'];
            return max_index

        data = codes['data'][0]['trend']['max']

        print "data\n", data

        return data
    else:
        data = None;
        return data

###计算头条指数
def toutiao_index(name,start_date,end_time):
    search_name = name.encode('utf-8')
    ##获取要搜索的节目的微指数的id
    url_name = urllib2.quote(search_name)
    url = 'https://index.toutiao.com/api/keyword/trends?region=0&category=0&keyword={}&start={}&end={}&is_hourly=0'.format(url_name,start_date,end_time)

    req = urllib2.Request(url=url)
    res = urllib2.urlopen(req)
    res = res.read()

    if res.find("<!DOCTYPE" ) != -1:
        code = requests.get(url).text
        if code.find("<!DOCTYPE".encode('utf-8') ) != -1:
            return '没有该关键字'
        code = json.loads(code)
        code = code['trends'].values()[0][0]
        print '头条指数', code
        return code

    res = json.loads(res)
    res = res['trends'].values()[0]
    res = max(res)
    print '头条指数',res
    return res


###返回节目信息
def Get_program_information():
    try:  ###初始化数据库连接
        pool=PooledDB(creator=MySQLdb,maxcached=2,maxshared=2,maxconnections=2,host='********', user='****', passwd='****', db='****', port=3306,charset='utf8')
        conn=pool.connection()
        sql = "SELECT programid AS pid,programname AS pnamw,off_line_time AS end_time FROM CMS_program"
    except MySQLdb.OperationalError:
        print ("local database can not link")
        conn = None
    if conn!=None:
        result=pd.read_sql(sql,conn)
        conn.close()
    else:
        result=None
        print "local database link error"
    return result

##建立一个舆情指数表
def create_program_public_sentiment_index():
    try:
        conn = MySQLdb.connect(host='********', user='****', passwd='****', db='****', port=3306,
                               charset='utf8')
        cur = conn.cursor()
        cur.execute('drop table if exists program_public_sentiment_index;')
        cur.execute('create table program_public_sentiment_index (programid varchar(50),programname varchar(50),data_time int(8),weibo_data varchar(50),toutiao_data varchar(50),baidu_data varchar(50),status int(11) NOT NULL);')
        conn.commit()
        cur.close
        conn.close()
        print 'program_public_sentiment_index  table is create!'
    except:
        print 'program_public_sentiment_index table create fail!'

###插入数据
def data_insert(program_index):
    try:
         conn = MySQLdb.connect(host='********', user='****', passwd='****', db='****', port=3306,
                               charset='utf8')
         cur = conn.cursor()
         sql = 'insert into program_public_sentiment_index  values(' + ','.join(map(lambda o: "%s", range(0, 7))) + ')'
         cur.execute(sql, program_index)
         conn.commit()
    except MySQLdb.Error,e:
        print "Mysql Error %d: %s" % (e.args[0], e.args[1])

def do_sth():
    create_program_public_sentiment_index()
    calculate_date = datetime.datetime.now() - datetime.timedelta(days=1)
    calculate_date1 = datetime.datetime.now() - datetime.timedelta(days=7)
    e_date = calculate_date.date().strftime('%Y%m%d')
    s_date = calculate_date1.date().strftime('%Y%m%d')

    program_pid = Get_program_information()
    program_pid_dict = {}
    program_pid_dict['pid'] = program_pid['pid'].tolist()
    program_pid_dict['pnamw'] = program_pid['pnamw'].tolist()
    program_pid_dict['end_time'] = program_pid['end_time'].tolist()
    try:
        conn = MySQLdb.connect(host='********', user='****', passwd='****', db='****', port=3306,
                               charset='utf8')
        cur = conn.cursor()
        for i, pid in enumerate(program_pid_dict['pid']):
            pnamw = program_pid_dict['pnamw'][i]
            end_time = program_pid_dict['end_time'][i]
            if not end_time:
                end_time = calculate_date
            end_time = end_time.strftime('%Y%m%d')
            end_time = datetime.datetime.strptime(end_time, "%Y%m%d") + datetime.timedelta(days=60)
            if (datetime.datetime.now() > end_time):
                continue
            weibo_data = weibo_index(pnamw,s_date, e_date)
            toutiao_data = toutiao_index(pnamw, s_date, e_date)
            baidu_data = None
            status = 0
            _data = list()
            _data.extend((pid, pnamw, e_date, weibo_data, toutiao_data,baidu_data,status))
            data_insert(_data)

    except:
        print "fail"



if __name__ == '__main__':
    do_sth()
    _baidu_index()
    # schedule.every(5).minutes.do(do_sth)
    # # schedule.every().monday.at("1:00").do(job)
    # while True:
    #     schedule.run_pending()
    #     time.sleep(1)











